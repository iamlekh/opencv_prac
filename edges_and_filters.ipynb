{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Edges and Applying Image Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "rows, cols = img.shape[:2]\n",
    "kernel_identity = np.array([[0,0,0], [0,1,0], [0,0,0]])\n",
    "kernel_3x3 = np.ones((3,3), np.float32) / 9.0\n",
    "kernel_5x5 = np.ones((5,5), np.float32) / 25.0\n",
    "cv2.imshow('Original', img)\n",
    "output = cv2.filter2D(img, -1, kernel_identity)\n",
    "cv2.imshow('Identity filter', output)\n",
    "output = cv2.filter2D(img, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 filter', output)\n",
    "output = cv2.filter2D(img, -1, kernel_5x5)\n",
    "cv2.imshow('5x5 filter', output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.blur(img, (1,1))\n",
    "cv2.imshow('blur', output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('shape.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "rows, cols = img.shape\n",
    "sobel_horizontal = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_vertical = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Sobel horizontal', sobel_horizontal)\n",
    "cv2.imshow('Sobel vertical', sobel_vertical)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(img, 50, 240)\n",
    "cv2.imshow('canny', canny)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "cv2.imshow('Original', img)\n",
    "size = 5\n",
    "# generating the kernel\n",
    "kernel_motion_blur = np.zeros((size, size))\n",
    "kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "kernel_motion_blur = kernel_motion_blur / size\n",
    "# applying the kernel to the input image\n",
    "output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "cv2.imshow('Motion Blur', output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "cv2.imshow('Original', img)\n",
    "# generating thekernels\n",
    "kernel_sharpen_1= np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "kernel_sharpen_2= np.array([[1,1,1], [1,-7,1], [1,1,1]])\n",
    "kernel_sharpen_3= np.array([[-1,-1,-1,-1,-1],\n",
    "                            [-1,2,2,2,-1],\n",
    "                            [-1,2,8,2,-1],\n",
    "                            [-1,2,2,2,-1],\n",
    "                            [-1,-1,-1,-1,-1]]) / 8.0\n",
    "# applying different kernelsto the input image\n",
    "output_1 =cv2.filter2D(img,-1, kernel_sharpen_1)\n",
    "output_2 =cv2.filter2D(img,-1, kernel_sharpen_2)\n",
    "output_3 =cv2.filter2D(img,-1, kernel_sharpen_3)\n",
    "\n",
    "cv2.imshow('Sharpening', output_1)\n",
    "cv2.imshow('Excessive Sharpening', output_2)\n",
    "cv2.imshow('Edge Enhancement', output_3)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img_emboss_input = cv2.imread('pic.jpeg')\n",
    "# generating the kernels\n",
    "kernel_emboss_1 = np.array([[0,-1,-1],\n",
    "                            [1,0,-1],\n",
    "                            [1,1,0]])\n",
    "kernel_emboss_2 = np.array([[-1,-1,0],\n",
    "                            [-1,0,1],\n",
    "                            [0,1,1]])\n",
    "kernel_emboss_3 = np.array([[1,0,0],\n",
    "                            [0,0,0],\n",
    "                            [0,0,-1]])\n",
    "# converting the image to grayscale\n",
    "gray_img = cv2.cvtColor(img_emboss_input,cv2.COLOR_BGR2GRAY)\n",
    "# applying the kernels to the grayscale image and adding the offset\n",
    "output_1 =cv2.filter2D(gray_img, -1, kernel_emboss_1) +128\n",
    "output_2 =cv2.filter2D(gray_img, -1, kernel_emboss_2) +128\n",
    "output_3 =cv2.filter2D(gray_img, -1, kernel_emboss_3) +128\n",
    "\n",
    "\n",
    "cv2.imshow('Input', img_emboss_input)\n",
    "cv2.imshow('Embossing - South West', output_1)\n",
    "cv2.imshow('Embossing - South East', output_2)\n",
    "cv2.imshow('Embossing - North West', output_3)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erosion and dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg', 0)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vignette filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "rows, cols = img.shape[:2]\n",
    "# generating vignette mask using Gaussian kernels\n",
    "kernel_x = cv2.getGaussianKernel(cols,200)\n",
    "kernel_y = cv2.getGaussianKernel(rows,200)\n",
    "kernel = kernel_y * kernel_x.T\n",
    "mask = 255 * kernel / np.linalg.norm(kernel)\n",
    "output = np.copy(img)\n",
    "# applying the mask to each channel in the input image\n",
    "for i in range(3):\n",
    "    output[:,:,i] = output[:,:,i] * mask\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Vignette', output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "rows, cols = img.shape[:2]\n",
    "# generating vignette mask using Gaussian kernels\n",
    "kernel_x = cv2.getGaussianKernel(int(1.5*cols),200)\n",
    "kernel_y = cv2.getGaussianKernel(int(1.5*rows),200)\n",
    "kernel = kernel_y * kernel_x.T\n",
    "mask = 255 * kernel / np.linalg.norm(kernel)\n",
    "mask = mask[int(0.5*rows):, int(0.5*cols):]\n",
    "output = np.copy(img)\n",
    "# applying the mask to each channel in the input image\n",
    "for i in range(3):\n",
    "    output[:,:,i] = output[:,:,i] * mask\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Vignette with shifted focus', output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contrast in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg', 0)\n",
    "# equalize the histogram of the input image\n",
    "histeq = cv2.equalizeHist(img)\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Histogram equalized', histeq)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('pic.jpeg')\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "# equalize the histogram of the Y channel\n",
    "img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "# convert the YUV image back to RGB format\n",
    "img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "cv2.imshow('Color input image', img)\n",
    "cv2.imshow('Histogram equalized', img_output)\n",
    "cv2.waitKey()           \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
